{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8dbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('omw-1.4')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "\n",
    "import emoji\n",
    "from emot.emo_unicode import UNICODE_EMOJI,EMOTICONS_EMO,EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa13899",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../data/cyberbullying_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92b49c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47692, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65e10f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1a8af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text            0\n",
       "cyberbullying_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02a4ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='cyberbullying_type'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(x=tweets['cyberbullying_type'].value_counts().index, y=tweets['cyberbullying_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309653ec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d724a",
   "metadata": {},
   "source": [
    "### Extract hashtags, mentions, links and emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f24d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(self):\n",
    "    regex = \"#(\\w+)\"\n",
    "    hashtag_list = re.findall(regex, self)\n",
    "    l=[]\n",
    "    for x in hashtag_list:\n",
    "        x = x.lower()\n",
    "        x = re.sub(r\"[^a-zA-Z ]+\", '', x)\n",
    "        l.append(x)\n",
    "    if len(hashtag_list) > 0:\n",
    "        return ' '.join(hashtag_list)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def extract_tags(self):\n",
    "    regex = \"@(\\w+)\"\n",
    "    name_tag = re.findall(regex, self)\n",
    "    l=[]\n",
    "    for x in name_tag:\n",
    "        x = x.lower()\n",
    "        x = re.sub(r\"[^a-zA-Z ]+\", '', x)\n",
    "        l.append(x)\n",
    "    if len(l) > 0:\n",
    "        return ' '.join(l)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def extract_links(self):\n",
    "    regex = r'(https?://\\S+)'\n",
    "    url_list = re.findall(regex, self)\n",
    "    l=[]\n",
    "    for x in url_list:\n",
    "        x = x.lower()\n",
    "        x = re.sub(r\"[^a-zA-Z ]+\", '', x)\n",
    "        l.append(x)\n",
    "    if len(url_list) > 0:\n",
    "        return ' '.join(url_list)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def extract_emojis(self):\n",
    "    emoji_list = ''.join(c for c in self if c in emoji.UNICODE_EMOJI['en'])\n",
    "    text_emoji =  ''.join(emoji.demojize(x) for x in emoji_list if x)\n",
    "    regex = r\"\\:(.*?)\\:\"\n",
    "    text_emoji =  re.findall(regex, text_emoji)\n",
    "    if len(text_emoji) > 0:\n",
    "        return ' '.join(text_emoji)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538fe230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet_text'] = tweets['tweet_text'].str.lower()\n",
    "tweets['hash_tag']   = tweets['tweet_text'].apply(extract_hashtags)\n",
    "tweets['name_tag']   = tweets['tweet_text'].apply(extract_tags)\n",
    "tweets['url_tag']    = tweets['tweet_text'].apply(extract_links)\n",
    "tweets['emoji_tag']  = tweets['tweet_text'].apply(extract_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b35d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>hash_tag</th>\n",
       "      <th>name_tag</th>\n",
       "      <th>url_tag</th>\n",
       "      <th>emoji_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>katandandre mkr</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>aussietv mkr theblock imacelebrityau today sun...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>xochitlsuckkks</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jason_gio meh. :p  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>jasongio</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rudhoeenglish this is an isis account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>rudhoeenglish</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "3  @jason_gio meh. :p  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @rudhoeenglish this is an isis account pretend...  not_cyberbullying   \n",
       "\n",
       "                                            hash_tag        name_tag url_tag  \\\n",
       "0                                    katandandre mkr                           \n",
       "1  aussietv mkr theblock imacelebrityau today sun...                           \n",
       "2                                                     xochitlsuckkks           \n",
       "3                                                           jasongio           \n",
       "4                                                      rudhoeenglish           \n",
       "\n",
       "  emoji_tag  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca321e55",
   "metadata": {},
   "source": [
    "### Remove the symbols and numbers from tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d36f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet_text'] = tweets['tweet_text'].apply(lambda x: re.sub(r\"[^a-zA-Z ]+\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c76ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>hash_tag</th>\n",
       "      <th>name_tag</th>\n",
       "      <th>url_tag</th>\n",
       "      <th>emoji_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words katandandre your food was crapi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>katandandre mkr</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is aussietv so white mkr theblock imaceleb...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>aussietv mkr theblock imacelebrityau today sun...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xochitlsuckkks a classy whore or more red velv...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>xochitlsuckkks</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jasongio meh p  thanks for the heads up but no...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>jasongio</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rudhoeenglish this is an isis account pretendi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>rudhoeenglish</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0  in other words katandandre your food was crapi...  not_cyberbullying   \n",
       "1  why is aussietv so white mkr theblock imaceleb...  not_cyberbullying   \n",
       "2  xochitlsuckkks a classy whore or more red velv...  not_cyberbullying   \n",
       "3  jasongio meh p  thanks for the heads up but no...  not_cyberbullying   \n",
       "4  rudhoeenglish this is an isis account pretendi...  not_cyberbullying   \n",
       "\n",
       "                                            hash_tag        name_tag url_tag  \\\n",
       "0                                    katandandre mkr                           \n",
       "1  aussietv mkr theblock imacelebrityau today sun...                           \n",
       "2                                                     xochitlsuckkks           \n",
       "3                                                           jasongio           \n",
       "4                                                      rudhoeenglish           \n",
       "\n",
       "  emoji_tag  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096ac77",
   "metadata": {},
   "source": [
    "### Remove the hashtags, mentions, url and emojis from tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ea2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text,dirt):\n",
    "    dirt = dirt.split()\n",
    "    for x in dirt:\n",
    "        text = text.replace(x,'')\n",
    "        text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7641e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet_text'] = tweets.apply(lambda row :clean_text(row['tweet_text'],row['name_tag']),axis=1)\n",
    "tweets['tweet_text'] = tweets.apply(lambda row :clean_text(row['tweet_text'],row['hash_tag']),axis=1)\n",
    "tweets['tweet_text'] = tweets.apply(lambda row :clean_text(row['tweet_text'],row['url_tag']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d03d53cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>hash_tag</th>\n",
       "      <th>name_tag</th>\n",
       "      <th>url_tag</th>\n",
       "      <th>emoji_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words your food was crapilicious</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>katandandre mkr</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is so white studio</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>aussietv mkr theblock imacelebrityau today sun...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>xochitlsuckkks</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>jasongio</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>rudhoeenglish</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0          in other words your food was crapilicious  not_cyberbullying   \n",
       "1                             why is so white studio  not_cyberbullying   \n",
       "2         a classy whore or more red velvet cupcakes  not_cyberbullying   \n",
       "3  meh p thanks for the heads up but not too conc...  not_cyberbullying   \n",
       "4  this is an isis account pretending to be a kur...  not_cyberbullying   \n",
       "\n",
       "                                            hash_tag        name_tag url_tag  \\\n",
       "0                                    katandandre mkr                           \n",
       "1  aussietv mkr theblock imacelebrityau today sun...                           \n",
       "2                                                     xochitlsuckkks           \n",
       "3                                                           jasongio           \n",
       "4                                                      rudhoeenglish           \n",
       "\n",
       "  emoji_tag  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e270e05",
   "metadata": {},
   "source": [
    "### Process the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9add8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_accent(string):\n",
    "    string = string.replace('á', 'a')\n",
    "    string = string.replace('à', 'a')\n",
    "    string = string.replace('â', 'a')\n",
    "\n",
    "    string = string.replace('é', 'e')\n",
    "    string = string.replace('è', 'e')\n",
    "    string = string.replace('ê', 'e')\n",
    "    string = string.replace('ë', 'e')\n",
    "\n",
    "    string = string.replace('î', 'i')\n",
    "    string = string.replace('ï', 'i')\n",
    "\n",
    "    string = string.replace('ö', 'o')\n",
    "    string = string.replace('ô', 'o')\n",
    "    string = string.replace('ò', 'o')\n",
    "    string = string.replace('ó', 'o')\n",
    "\n",
    "    string = string.replace('ù', 'u')\n",
    "    string = string.replace('û', 'u')\n",
    "    string = string.replace('ü', 'u')\n",
    "\n",
    "    string = string.replace('ç', 'c')\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee35c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9170be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    # Remove Hashtag, Mention, https, www.asdfd, dsfadsf.com\n",
    "    pattern = re.compile(r\"(#[A-Za-z0-9]+|@[A-Za-z0-9]+|https?://\\S+|www\\.\\S+|\\S+\\.[a-z]+|RT @)\")\n",
    "    text = pattern.sub('', str(text))\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Make all text lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace accented letters\n",
    "    text = normalize_accent(text)\n",
    "\n",
    "    # Lemmatize word and remove stopwords\n",
    "    text = \" \".join([lemma.lemmatize(word) for word in str(text).split() if word.isalpha() and word not in STOPWORDS])\n",
    "\n",
    "    # Remove Punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c85aade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>hash_tag</th>\n",
       "      <th>name_tag</th>\n",
       "      <th>url_tag</th>\n",
       "      <th>emoji_tag</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words your food was crapilicious</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>katandandre mkr</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>word food crapilicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is so white studio</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>aussietv mkr theblock imacelebrityau today sun...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>white studio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>xochitlsuckkks</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>classy whore red velvet cupcake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>jasongio</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>meh p thanks head concerned another angry dude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>rudhoeenglish</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>isi account pretending kurdish account like is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0          in other words your food was crapilicious  not_cyberbullying   \n",
       "1                             why is so white studio  not_cyberbullying   \n",
       "2         a classy whore or more red velvet cupcakes  not_cyberbullying   \n",
       "3  meh p thanks for the heads up but not too conc...  not_cyberbullying   \n",
       "4  this is an isis account pretending to be a kur...  not_cyberbullying   \n",
       "\n",
       "                                            hash_tag        name_tag url_tag  \\\n",
       "0                                    katandandre mkr                           \n",
       "1  aussietv mkr theblock imacelebrityau today sun...                           \n",
       "2                                                     xochitlsuckkks           \n",
       "3                                                           jasongio           \n",
       "4                                                      rudhoeenglish           \n",
       "\n",
       "  emoji_tag                                        clean_tweet  \n",
       "0                                       word food crapilicious  \n",
       "1                                                 white studio  \n",
       "2                              classy whore red velvet cupcake  \n",
       "3            meh p thanks head concerned another angry dude...  \n",
       "4            isi account pretending kurdish account like is...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['clean_tweet'] = tweets['tweet_text']\n",
    "tweets['clean_tweet'] = tweets['clean_tweet'].apply(lambda text: clean_tweet(text))\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef142935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text            0\n",
       "cyberbullying_type    0\n",
       "hash_tag              0\n",
       "name_tag              0\n",
       "url_tag               0\n",
       "emoji_tag             0\n",
       "clean_tweet           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f80e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(\"../data/cleaned_cyberbullying_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d9ed6e",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8556a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for s in list(tweets.cyberbullying_type.value_counts().index):\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     wordcloud = WordCloud(min_font_size=5, max_words=1000, width=1600 , height=800 , stopwords=STOPWORDS).generate(str(tweets[tweets[\"cyberbullying_type\"] == s].clean_tweet))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(wordcloud)\n",
    "#     plt.title(s)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340ea11",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4074530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../data/cleaned_cyberbullying_tweets.csv\")\n",
    "tweets.hash_tag = tweets.hash_tag.fillna(\"\")\n",
    "tweets.emoji_tag = tweets.emoji_tag.fillna(\"\")\n",
    "tweets.clean_tweet = tweets.clean_tweet.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a16c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47692, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f364f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text              134\n",
       "cyberbullying_type        0\n",
       "hash_tag                  0\n",
       "name_tag              29599\n",
       "url_tag               43391\n",
       "emoji_tag                 0\n",
       "clean_tweet               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45fba3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>hash_tag</th>\n",
       "      <th>name_tag</th>\n",
       "      <th>url_tag</th>\n",
       "      <th>emoji_tag</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words your food was crapilicious</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>katandandre mkr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>word food crapilicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is so white studio</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>aussietv mkr theblock imacelebrityau today sun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>white studio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a classy whore or more red velvet cupcakes</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>xochitlsuckkks</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>classy whore red velvet cupcake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meh p thanks for the heads up but not too conc...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>jasongio</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>meh p thanks head concerned another angry dude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is an isis account pretending to be a kur...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td></td>\n",
       "      <td>rudhoeenglish</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>isi account pretending kurdish account like is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text cyberbullying_type  \\\n",
       "0          in other words your food was crapilicious  not_cyberbullying   \n",
       "1                             why is so white studio  not_cyberbullying   \n",
       "2         a classy whore or more red velvet cupcakes  not_cyberbullying   \n",
       "3  meh p thanks for the heads up but not too conc...  not_cyberbullying   \n",
       "4  this is an isis account pretending to be a kur...  not_cyberbullying   \n",
       "\n",
       "                                            hash_tag        name_tag url_tag  \\\n",
       "0                                    katandandre mkr             NaN     NaN   \n",
       "1  aussietv mkr theblock imacelebrityau today sun...             NaN     NaN   \n",
       "2                                                     xochitlsuckkks     NaN   \n",
       "3                                                           jasongio     NaN   \n",
       "4                                                      rudhoeenglish     NaN   \n",
       "\n",
       "  emoji_tag                                        clean_tweet  \n",
       "0                                       word food crapilicious  \n",
       "1                                                 white studio  \n",
       "2                              classy whore red velvet cupcake  \n",
       "3            meh p thanks head concerned another angry dude...  \n",
       "4            isi account pretending kurdish account like is...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f4f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 4555)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "hshtg_vectorizer = TfidfVectorizer() #max_features=1000\n",
    "hshtg_vec = hshtg_vectorizer.fit_transform(tweets.hash_tag)\n",
    "print(hshtg_vec.shape)\n",
    "# print(hshtg_vectorizer.get_feature_names())\n",
    "tfidf_hashtags = hshtg_vectorizer.get_feature_names()\n",
    "\n",
    "hshtg_tfidf = pd.DataFrame(hshtg_vec.todense(), columns=tfidf_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec758600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 174)\n"
     ]
    }
   ],
   "source": [
    "emoji_vectorizer = TfidfVectorizer()\n",
    "emoji_vec = emoji_vectorizer.fit_transform(tweets.emoji_tag)\n",
    "print(emoji_vec.shape)\n",
    "# print(emoji_vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_emojis = emoji_vectorizer.get_feature_names()\n",
    "\n",
    "emoji_tfidf = pd.DataFrame(emoji_vec.todense(), columns=tfidf_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a0c437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 2791)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(min_df=.0005, max_df=.90)\n",
    "tfidf = tfidf_vec.fit_transform(tweets.clean_tweet)\n",
    "print(tfidf.shape)\n",
    "tfidf_tweet_terms = tfidf_vec.get_feature_names()\n",
    "\n",
    "tweets_tfidf = pd.DataFrame(tfidf.todense(), columns=tfidf_tweet_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e322df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 4555)\n",
      "(47692, 174)\n",
      "(47692, 2791)\n"
     ]
    }
   ],
   "source": [
    "print(hshtg_tfidf.shape)\n",
    "print(emoji_tfidf.shape)\n",
    "print(tweets_tfidf.shape) # total 7810 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1388eaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 7522)\n"
     ]
    }
   ],
   "source": [
    "final_tweets = pd.concat([tweets[['tweet_text','cyberbullying_type']], tweets_tfidf, hshtg_tfidf, emoji_tfidf], axis=1)\n",
    "print(final_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a20b3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 7007)\n"
     ]
    }
   ],
   "source": [
    "final_tweets = final_tweets.loc[:,~final_tweets.columns.duplicated()]\n",
    "print(final_tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b3599",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116bbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_tweets.drop(['tweet_text','cyberbullying_type'], axis=1)\n",
    "Y = final_tweets.cyberbullying_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16af338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTreeFeatImp(X_train, y_train):\n",
    "    grid_params = {'max_depth' : [int(x) for x in np.linspace(190, 220, num = 20)],#[85, 87, 89, 90, 91, 93],\n",
    "                   'criterion' : ['entropy', 'gini'], \n",
    "                   'splitter' : ['best', 'random'] }\n",
    "    \n",
    "        \n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_cv = GridSearchCV(estimator = dt_clf, \n",
    "                                   param_grid = grid_params, \n",
    "                                   cv = 7, \n",
    "                                   verbose=2, \n",
    "                                   n_jobs = -1, \n",
    "                                   scoring = 'f1_weighted')\n",
    "    \n",
    "    dt_cv.fit(X_train, y_train.values.ravel())\n",
    "    dt_best = dt_cv.best_estimator_\n",
    "    print(\"dt_cv.best_params_\", dt_cv.best_params_)\n",
    "    y_predicted = dt_best.predict(X_train)\n",
    "    dt_accuracy = accuracy_score(y_train, y_predicted)\n",
    "    dt_f1 = f1_score(y_train, y_predicted, average=\"weighted\")\n",
    "    \n",
    "    print(\"In sample accurancy = \", dt_accuracy)\n",
    "    print(\"In sample f1 = \", dt_f1)\n",
    "    print('Best Params = ', dt_cv.best_params_)\n",
    "    \n",
    "    feat_imp = dt_best.feature_importances_\n",
    "    return feat_imp\n",
    "\n",
    "\n",
    "# # define the model\n",
    "# model = DecisionTreeClassifier()\n",
    "# # fit the model\n",
    "# model.fit(X, Y)\n",
    "# # get importance\n",
    "# imp_features = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f9530f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 80 candidates, totalling 560 fits\n",
      "dt_cv.best_params_ {'criterion': 'gini', 'max_depth': 215, 'splitter': 'random'}\n",
      "In sample accurancy =  0.9231736978948252\n",
      "In sample f1 =  0.9237135896095231\n",
      "Best Params =  {'criterion': 'gini', 'max_depth': 215, 'splitter': 'random'}\n",
      "CPU times: user 26.6 s, sys: 5.05 s, total: 31.6 s\n",
      "Wall time: 52min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feat_imp = decisionTreeFeatImp(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99870399",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_index = feat_imp.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a9a13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = list(X.columns[feat_imp_index[:1757]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ae2e5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70a380",
   "metadata": {},
   "source": [
    "We extract only the necessary columns to a new dataframe that will be used henceforth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7260f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mod = X[imp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab4fc216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_models = pd.concat([X_mod, Y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e1f1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_models.to_csv(\"../data/df_for_models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce75361",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead58c8",
   "metadata": {},
   "source": [
    "## Multi-class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e008c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/df_for_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b771d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['cyberbullying_type'], axis=1)\n",
    "Y = df.cyberbullying_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86901da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47692, 1757)\n",
      "(47692,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946d9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b22b44",
   "metadata": {},
   "source": [
    "## Binary class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844edbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyberbullying        39747\n",
       "not_cyberbullying     7945\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df = pd.read_csv(\"../data/df_for_models.csv\")\n",
    "binary_df[\"cyberbullying_type\"] = binary_df[\"cyberbullying_type\"].apply(lambda x: \"not_cyberbullying\" if x == \"not_cyberbullying\" else \"cyberbullying\")\n",
    "binary_df[\"cyberbullying_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12b771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin = binary_df.drop(['cyberbullying_type'], axis=1)\n",
    "Y_bin = binary_df.cyberbullying_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1978d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin_train, X_bin_test, y_bin_train, y_bin_test = train_test_split(X_bin, Y_bin, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb80e9",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87710ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTreeClassifier(X_train, X_test, y_train, y_test):\n",
    "    grid_params = {'max_depth' : [int(x) for x in np.linspace(180, 200, num = 20)],\n",
    "                   'criterion' : ['entropy', 'gini'], \n",
    "                   'splitter' : ['best', 'random'] }\n",
    "    \n",
    "        \n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_cv = GridSearchCV(estimator = dt_clf, \n",
    "                                   param_grid = grid_params, \n",
    "                                   cv = 7, \n",
    "                                   verbose=2, \n",
    "                                   n_jobs = -1, \n",
    "                                   scoring = 'f1_weighted')\n",
    "    \n",
    "    dt_cv.fit(X_train, y_train.values.ravel())\n",
    "    print(\"dt_cv.best_params_\", dt_cv.best_params_)\n",
    "    \n",
    "    dt_best = dt_cv.best_estimator_\n",
    "    y_predicted = dt_best.predict(X_test)\n",
    "    dt_accuracy = accuracy_score(y_test, y_predicted)\n",
    "    dt_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "    \n",
    "    print(\"dt_accuracy, dt_f1\", dt_accuracy, dt_f1)\n",
    "    \n",
    "    return dt_accuracy, dt_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6712dfc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 80 candidates, totalling 560 fits\n",
      "dt_cv.best_params_ {'criterion': 'gini', 'max_depth': 189, 'splitter': 'random'}\n",
      "dt_accuracy, dt_f1 0.800461280402572 0.7996694355636723\n",
      "a = 0.800461280402572\n",
      "f = 0.7996694355636723\n",
      "CPU times: user 8.74 s, sys: 637 ms, total: 9.38 s\n",
      "Wall time: 14min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,f = decisionTreeClassifier(X_train, X_test, y_train, y_test)\n",
    "print(\"a =\", a)\n",
    "print(\"f =\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97987067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 80 candidates, totalling 560 fits\n",
      "dt_cv.best_params_ {'criterion': 'entropy', 'max_depth': 190, 'splitter': 'random'}\n",
      "dt_accuracy, dt_f1 0.8541375454291306 0.8384417124230957\n",
      "a_bin = 0.8541375454291306\n",
      "f_bin = 0.8384417124230957\n",
      "CPU times: user 8.24 s, sys: 779 ms, total: 9.02 s\n",
      "Wall time: 14min 58s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.6s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  13.3s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  13.7s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  13.9s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  14.9s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  11.3s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  11.1s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.0s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  12.7s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  13.4s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  11.5s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  13.9s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  13.5s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.6s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.0s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.5s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  15.3s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  10.7s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  12.4s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.3s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  11.6s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  10.5s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  12.9s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  11.9s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  12.9s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  12.2s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  12.4s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.8s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  12.9s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  12.5s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.4s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  13.0s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  13.4s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  13.4s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  13.4s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  14.7s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  11.3s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.9s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  13.0s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  11.1s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  12.7s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  13.7s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  12.9s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.8s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.9s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  13.9s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  15.0s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  15.7s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.8s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  15.9s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  13.7s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.1s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  15.3s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  12.7s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  15.6s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.8s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  15.9s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  12.7s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  14.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.6s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  12.5s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  13.4s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  14.0s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  11.2s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.5s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  14.7s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  11.2s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.8s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  11.3s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  12.3s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  13.1s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  14.3s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.4s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.9s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.5s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.4s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.2s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  12.2s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.6s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.3s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  13.3s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  15.9s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  15.3s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  15.3s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.7s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  16.7s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  11.8s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.6s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  11.6s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  13.0s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  14.4s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  11.3s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=  10.7s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  13.1s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  11.5s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  14.2s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  11.1s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  13.9s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.8s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.7s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  13.9s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.3s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  15.4s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  13.2s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  15.7s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.7s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  15.3s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  17.3s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  10.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.8s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  13.5s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  13.5s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  13.6s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.4s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.7s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  12.8s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  13.5s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  11.1s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  13.7s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  13.7s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.8s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.8s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.3s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  10.8s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  11.9s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.9s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  10.5s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.3s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  15.3s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  16.2s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  13.2s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  15.0s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  15.4s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  13.6s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.5s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.5s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=   9.6s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.7s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  11.2s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  13.1s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  14.5s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  13.4s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.4s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.3s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.3s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  13.6s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  11.7s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  13.4s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  13.6s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  13.0s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  10.6s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.1s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  15.4s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  16.3s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.7s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.3s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  15.4s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  15.3s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  16.0s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  13.1s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=   9.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.9s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  13.7s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  13.3s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  15.7s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.3s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  11.2s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  14.5s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.7s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  11.3s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.9s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  11.1s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  11.2s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  13.1s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.7s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.6s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.5s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  12.9s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.3s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.3s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  16.5s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.7s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.5s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  15.4s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  12.8s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  15.3s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  15.3s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.1s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  11.0s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.3s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.0s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  13.8s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  14.8s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  13.3s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  13.1s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  14.1s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  13.4s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  13.7s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.5s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  13.3s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  13.9s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.3s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  15.2s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  16.9s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  13.3s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.5s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  15.3s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  16.6s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=   8.0s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_bin,f_bin = decisionTreeClassifier(X_bin_train, X_bin_test, y_bin_train, y_bin_test)\n",
    "print(\"a_bin =\", a_bin)\n",
    "print(\"f_bin =\", f_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75326221",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b3a85",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c85c9663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  13.5s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.5s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  11.2s\n",
      "[CV] END ....criterion=entropy, max_depth=201, splitter=best; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=203, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=203, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=206, splitter=best; total time=  13.3s\n",
      "[CV] END ..criterion=entropy, max_depth=206, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=208, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=208, splitter=random; total time=  10.4s\n",
      "[CV] END ..criterion=entropy, max_depth=211, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=214, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=214, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=216, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=216, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=219, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=219, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=222, splitter=best; total time=  13.1s\n",
      "[CV] END ....criterion=entropy, max_depth=224, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=224, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=227, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=227, splitter=random; total time=  11.1s\n",
      "[CV] END ....criterion=entropy, max_depth=230, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.5s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  13.9s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  13.9s\n",
      "[CV] END .......criterion=gini, max_depth=201, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=201, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=203, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=203, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=206, splitter=best; total time=  15.2s\n",
      "[CV] END .......criterion=gini, max_depth=208, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=208, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=211, splitter=best; total time=  15.3s\n",
      "[CV] END .....criterion=gini, max_depth=211, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=214, splitter=best; total time=  15.4s\n",
      "[CV] END .....criterion=gini, max_depth=214, splitter=random; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=216, splitter=random; total time=  12.7s\n",
      "[CV] END .....criterion=gini, max_depth=216, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=219, splitter=best; total time=  14.5s\n",
      "[CV] END .......criterion=gini, max_depth=222, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=222, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=224, splitter=best; total time=  15.7s\n",
      "[CV] END .....criterion=gini, max_depth=224, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=227, splitter=best; total time=  16.1s\n",
      "[CV] END .......criterion=gini, max_depth=230, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=230, splitter=random; total time=  11.3s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  11.9s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  11.8s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.4s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.0s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=   9.7s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.2s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.8s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  10.4s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  13.5s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.7s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  13.3s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  13.5s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  11.1s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  11.9s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  13.5s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.6s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.3s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=   9.6s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=201, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=201, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=203, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=203, splitter=random; total time=  11.5s\n",
      "[CV] END ....criterion=entropy, max_depth=206, splitter=best; total time=  13.0s\n",
      "[CV] END ....criterion=entropy, max_depth=208, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=208, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=211, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=211, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=214, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=214, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=216, splitter=best; total time=  12.5s\n",
      "[CV] END ....criterion=entropy, max_depth=219, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=219, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=222, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=222, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=224, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=224, splitter=random; total time=  10.5s\n",
      "[CV] END ..criterion=entropy, max_depth=227, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=230, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=230, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.8s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  10.6s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  10.9s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.3s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.1s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.0s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.3s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=201, splitter=random; total time=  11.8s\n",
      "[CV] END .....criterion=gini, max_depth=201, splitter=random; total time=  10.9s\n",
      "[CV] END .....criterion=gini, max_depth=203, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=203, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=206, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=206, splitter=random; total time=  11.5s\n",
      "[CV] END .....criterion=gini, max_depth=208, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=208, splitter=random; total time=  11.6s\n",
      "[CV] END .....criterion=gini, max_depth=211, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=211, splitter=random; total time=  11.8s\n",
      "[CV] END .....criterion=gini, max_depth=214, splitter=random; total time=  12.2s\n",
      "[CV] END .......criterion=gini, max_depth=216, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=216, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=219, splitter=best; total time=  15.7s\n",
      "[CV] END .....criterion=gini, max_depth=219, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=222, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=222, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=224, splitter=best; total time=  14.7s\n",
      "[CV] END .......criterion=gini, max_depth=227, splitter=best; total time=  15.4s\n",
      "[CV] END .....criterion=gini, max_depth=227, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=230, splitter=best; total time=  15.9s\n",
      "[CV] END .....criterion=gini, max_depth=230, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=   9.7s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=   9.6s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=   9.7s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=   9.7s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.0s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  11.9s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.5s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.6s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.7s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  13.5s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.8s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  12.0s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  10.5s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  13.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  13.5s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.7s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=201, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=201, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=203, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=203, splitter=random; total time=  11.3s\n",
      "[CV] END ....criterion=entropy, max_depth=206, splitter=best; total time=  13.3s\n",
      "[CV] END ..criterion=entropy, max_depth=206, splitter=random; total time=  10.2s\n",
      "[CV] END ..criterion=entropy, max_depth=208, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=211, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=211, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=214, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=214, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=216, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=216, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=219, splitter=best; total time=  12.7s\n",
      "[CV] END ....criterion=entropy, max_depth=222, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=222, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=224, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=224, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=227, splitter=best; total time=  13.3s\n",
      "[CV] END ..criterion=entropy, max_depth=227, splitter=random; total time=  10.7s\n",
      "[CV] END ..criterion=entropy, max_depth=230, splitter=random; total time=  11.1s\n",
      "[CV] END ..criterion=entropy, max_depth=230, splitter=random; total time=  10.8s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  10.8s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  13.4s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  13.6s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  15.2s\n",
      "[CV] END .......criterion=gini, max_depth=201, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=201, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=203, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=203, splitter=random; total time=  12.2s\n",
      "[CV] END .......criterion=gini, max_depth=206, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=206, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=208, splitter=best; total time=  14.1s\n",
      "[CV] END .......criterion=gini, max_depth=211, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=211, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=214, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=214, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=216, splitter=best; total time=  15.6s\n",
      "[CV] END .......criterion=gini, max_depth=219, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=219, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=222, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=222, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=224, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=224, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=227, splitter=best; total time=  15.0s\n",
      "[CV] END .......criterion=gini, max_depth=230, splitter=best; total time=  15.4s\n",
      "[CV] END .....criterion=gini, max_depth=230, splitter=random; total time=  11.9s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.4s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=   9.6s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=   9.4s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  11.0s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=   9.4s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  11.8s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.0s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.0s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.3s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  13.3s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  10.8s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.3s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  13.2s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  13.4s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.1s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.1s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  15.0s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  10.5s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  13.8s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  15.1s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  14.1s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.6s\n",
      "[CV] END ..criterion=entropy, max_depth=201, splitter=random; total time=  10.5s\n",
      "[CV] END ..criterion=entropy, max_depth=201, splitter=random; total time=  10.3s\n",
      "[CV] END ..criterion=entropy, max_depth=203, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=206, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=206, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=208, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=208, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=211, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=211, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=214, splitter=best; total time=  12.8s\n",
      "[CV] END ....criterion=entropy, max_depth=216, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=216, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=219, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=219, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=222, splitter=best; total time=  13.2s\n",
      "[CV] END ..criterion=entropy, max_depth=222, splitter=random; total time=  10.5s\n",
      "[CV] END ..criterion=entropy, max_depth=224, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=227, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=227, splitter=random; total time=  11.2s\n",
      "[CV] END ....criterion=entropy, max_depth=230, splitter=best; total time=  12.9s\n",
      "[CV] END ..criterion=entropy, max_depth=230, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.0s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.4s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  15.1s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=201, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=201, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=203, splitter=best; total time=  15.2s\n",
      "[CV] END .......criterion=gini, max_depth=206, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=206, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=208, splitter=best; total time=  15.3s\n",
      "[CV] END .....criterion=gini, max_depth=208, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=211, splitter=best; total time=  15.4s\n",
      "[CV] END .......criterion=gini, max_depth=214, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=214, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=216, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=216, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=219, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=219, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=222, splitter=best; total time=  14.3s\n",
      "[CV] END .......criterion=gini, max_depth=224, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=224, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=227, splitter=best; total time=  15.7s\n",
      "[CV] END .....criterion=gini, max_depth=227, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=230, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=230, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=   9.0s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=   9.3s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=   9.4s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  11.3s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  11.9s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=   9.5s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.8s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=   9.6s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=   9.7s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=   9.9s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  10.5s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  13.4s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  13.3s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  13.4s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  13.6s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  15.1s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  13.8s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=  11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  11.0s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.4s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=   9.7s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.2s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=201, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=201, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=203, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=203, splitter=random; total time=  11.3s\n",
      "[CV] END ....criterion=entropy, max_depth=206, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=206, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=208, splitter=best; total time=  12.3s\n",
      "[CV] END ....criterion=entropy, max_depth=211, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=211, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=214, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=214, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=216, splitter=best; total time=  13.1s\n",
      "[CV] END ....criterion=entropy, max_depth=219, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=219, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=222, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=222, splitter=random; total time=  11.5s\n",
      "[CV] END ....criterion=entropy, max_depth=224, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=224, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=227, splitter=best; total time=  12.9s\n",
      "[CV] END ....criterion=entropy, max_depth=230, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=230, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  13.5s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  13.6s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=201, splitter=best; total time=  15.2s\n",
      "[CV] END .......criterion=gini, max_depth=203, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=203, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=206, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=206, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=208, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=208, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=211, splitter=best; total time=  14.0s\n",
      "[CV] END .......criterion=gini, max_depth=214, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=214, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=216, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=216, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=219, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=219, splitter=random; total time=  11.9s\n",
      "[CV] END .....criterion=gini, max_depth=222, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=224, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=224, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=227, splitter=best; total time=  15.9s\n",
      "[CV] END .....criterion=gini, max_depth=227, splitter=random; total time=  13.4s\n",
      "[CV] END .......criterion=gini, max_depth=230, splitter=best; total time=  16.0s\n",
      "[CV] END .....criterion=gini, max_depth=230, splitter=random; total time=   9.2s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  11.9s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.7s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.0s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.9s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.9s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=   9.7s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.0s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.6s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.7s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  10.7s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.1s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.8s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  10.7s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.6s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  13.5s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.9s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  13.9s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=   9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  13.8s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.6s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.7s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.6s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=201, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=201, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=203, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=203, splitter=random; total time=  10.9s\n",
      "[CV] END ..criterion=entropy, max_depth=206, splitter=random; total time=  11.1s\n",
      "[CV] END ....criterion=entropy, max_depth=208, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=208, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=211, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=211, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=214, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=214, splitter=random; total time=  10.5s\n",
      "[CV] END ..criterion=entropy, max_depth=216, splitter=random; total time=  10.6s\n",
      "[CV] END ..criterion=entropy, max_depth=216, splitter=random; total time=  10.3s\n",
      "[CV] END ..criterion=entropy, max_depth=219, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=222, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=222, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=224, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=224, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=227, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=227, splitter=random; total time=  11.2s\n",
      "[CV] END ....criterion=entropy, max_depth=230, splitter=best; total time=  13.2s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.8s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.6s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  12.4s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.8s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=201, splitter=best; total time=  13.9s\n",
      "[CV] END .....criterion=gini, max_depth=201, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=203, splitter=best; total time=  13.9s\n",
      "[CV] END .......criterion=gini, max_depth=206, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=206, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=208, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=208, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=211, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=211, splitter=random; total time=  12.9s\n",
      "[CV] END .......criterion=gini, max_depth=214, splitter=best; total time=  14.3s\n",
      "[CV] END .......criterion=gini, max_depth=216, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=216, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=219, splitter=best; total time=  15.5s\n",
      "[CV] END .....criterion=gini, max_depth=219, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=222, splitter=best; total time=  15.8s\n",
      "[CV] END .....criterion=gini, max_depth=222, splitter=random; total time=  11.8s\n",
      "[CV] END .....criterion=gini, max_depth=224, splitter=random; total time=  12.3s\n",
      "[CV] END .....criterion=gini, max_depth=224, splitter=random; total time=  12.3s\n",
      "[CV] END .....criterion=gini, max_depth=227, splitter=random; total time=  13.0s\n",
      "[CV] END .....criterion=gini, max_depth=227, splitter=random; total time=  12.1s\n",
      "[CV] END .....criterion=gini, max_depth=230, splitter=random; total time=  12.6s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=   9.7s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.5s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.2s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  11.8s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=192, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=   9.8s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.2s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=200, splitter=random; total time=  10.6s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.2s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  14.8s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.9s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.8s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  13.8s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  15.0s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=   9.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  13.9s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=185, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.6s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.2s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.3s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=201, splitter=best; total time=  12.8s\n",
      "[CV] END ....criterion=entropy, max_depth=203, splitter=best; total time=  12.3s\n",
      "[CV] END ..criterion=entropy, max_depth=203, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=206, splitter=best; total time=  13.1s\n",
      "[CV] END ..criterion=entropy, max_depth=206, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=208, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=208, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=211, splitter=best; total time=  12.5s\n",
      "[CV] END ....criterion=entropy, max_depth=214, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=214, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=216, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=216, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=219, splitter=best; total time=  13.1s\n",
      "[CV] END ..criterion=entropy, max_depth=219, splitter=random; total time=  10.3s\n",
      "[CV] END ..criterion=entropy, max_depth=222, splitter=random; total time=  10.9s\n",
      "[CV] END ....criterion=entropy, max_depth=224, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=224, splitter=random; total time=  11.5s\n",
      "[CV] END ....criterion=entropy, max_depth=227, splitter=best; total time=  13.0s\n",
      "[CV] END ..criterion=entropy, max_depth=227, splitter=random; total time=  11.5s\n",
      "[CV] END ....criterion=entropy, max_depth=230, splitter=best; total time=  12.8s\n",
      "[CV] END ..criterion=entropy, max_depth=230, splitter=random; total time=  10.7s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.3s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.8s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=201, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=201, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=203, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=203, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=206, splitter=best; total time=  13.9s\n",
      "[CV] END .......criterion=gini, max_depth=208, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=208, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=211, splitter=best; total time=  15.3s\n",
      "[CV] END .....criterion=gini, max_depth=211, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=214, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=214, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=216, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=219, splitter=best; total time=  15.4s\n",
      "[CV] END .....criterion=gini, max_depth=219, splitter=random; total time=  12.1s\n",
      "[CV] END .......criterion=gini, max_depth=222, splitter=best; total time=  15.7s\n",
      "[CV] END .....criterion=gini, max_depth=222, splitter=random; total time=  12.8s\n",
      "[CV] END .......criterion=gini, max_depth=224, splitter=best; total time=  16.1s\n",
      "[CV] END .......criterion=gini, max_depth=227, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=227, splitter=random; total time=  13.6s\n",
      "[CV] END .......criterion=gini, max_depth=230, splitter=best; total time=  15.7s\n",
      "[CV] END .....criterion=gini, max_depth=230, splitter=random; total time=  10.6s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  11.9s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.1s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=188, splitter=random; total time=   9.6s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  12.0s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  12.3s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.0s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  12.5s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.5s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.4s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  13.4s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  10.2s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  10.8s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  12.1s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  10.6s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  10.9s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  14.1s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  10.5s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=189, splitter=random; total time=  11.2s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  13.4s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  12.6s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  12.2s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=192, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.7s\n",
      "[CV] END .....criterion=gini, max_depth=196, splitter=random; total time=  11.0s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  14.5s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  15.1s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=   9.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  13.5s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=182, splitter=random; total time=   9.5s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.9s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  12.5s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=195, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=201, splitter=best; total time=  12.2s\n",
      "[CV] END ..criterion=entropy, max_depth=201, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=203, splitter=best; total time=  12.6s\n",
      "[CV] END ....criterion=entropy, max_depth=206, splitter=best; total time=  13.1s\n",
      "[CV] END ..criterion=entropy, max_depth=206, splitter=random; total time=  11.0s\n",
      "[CV] END ....criterion=entropy, max_depth=208, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=208, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=211, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=211, splitter=random; total time=  10.9s\n",
      "[CV] END ..criterion=entropy, max_depth=214, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=216, splitter=best; total time=  12.4s\n",
      "[CV] END ..criterion=entropy, max_depth=216, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=219, splitter=best; total time=  12.5s\n",
      "[CV] END ..criterion=entropy, max_depth=219, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=222, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=222, splitter=random; total time=  10.7s\n",
      "[CV] END ....criterion=entropy, max_depth=224, splitter=best; total time=  13.0s\n",
      "[CV] END ....criterion=entropy, max_depth=227, splitter=best; total time=  12.7s\n",
      "[CV] END ..criterion=entropy, max_depth=227, splitter=random; total time=  10.8s\n",
      "[CV] END ....criterion=entropy, max_depth=230, splitter=best; total time=  12.6s\n",
      "[CV] END ..criterion=entropy, max_depth=230, splitter=random; total time=  10.8s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  11.2s\n",
      "[CV] END .....criterion=gini, max_depth=182, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=185, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.8s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  11.6s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=201, splitter=best; total time=  13.9s\n",
      "[CV] END .......criterion=gini, max_depth=203, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=203, splitter=random; total time=  12.9s\n",
      "[CV] END .......criterion=gini, max_depth=206, splitter=best; total time=  15.2s\n",
      "[CV] END .....criterion=gini, max_depth=206, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=208, splitter=best; total time=  15.5s\n",
      "[CV] END .......criterion=gini, max_depth=211, splitter=best; total time=  14.9s\n",
      "[CV] END .....criterion=gini, max_depth=211, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=214, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=214, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=216, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=216, splitter=random; total time=  13.1s\n",
      "[CV] END .....criterion=gini, max_depth=219, splitter=random; total time=  11.9s\n",
      "[CV] END .......criterion=gini, max_depth=222, splitter=best; total time=  15.0s\n",
      "[CV] END .....criterion=gini, max_depth=222, splitter=random; total time=  11.8s\n",
      "[CV] END .......criterion=gini, max_depth=224, splitter=best; total time=  15.6s\n",
      "[CV] END .....criterion=gini, max_depth=224, splitter=random; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=227, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=227, splitter=random; total time=  12.2s\n",
      "[CV] END .......criterion=gini, max_depth=230, splitter=best; total time=  14.8s\n",
      "[CV] END ....criterion=entropy, max_depth=180, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=180, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=181, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=181, splitter=random; total time=   9.6s\n",
      "[CV] END ....criterion=entropy, max_depth=182, splitter=best; total time=  12.1s\n",
      "[CV] END ....criterion=entropy, max_depth=183, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=183, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=184, splitter=best; total time=  11.4s\n",
      "[CV] END ..criterion=entropy, max_depth=184, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=185, splitter=best; total time=  11.9s\n",
      "[CV] END ....criterion=entropy, max_depth=186, splitter=best; total time=  11.7s\n",
      "[CV] END ..criterion=entropy, max_depth=186, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=187, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=187, splitter=random; total time=   9.8s\n",
      "[CV] END ....criterion=entropy, max_depth=188, splitter=best; total time=  12.2s\n",
      "[CV] END ....criterion=entropy, max_depth=189, splitter=best; total time=  11.5s\n",
      "[CV] END ..criterion=entropy, max_depth=189, splitter=random; total time=   9.9s\n",
      "[CV] END ....criterion=entropy, max_depth=190, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=190, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=191, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=191, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=192, splitter=best; total time=  11.8s\n",
      "[CV] END ....criterion=entropy, max_depth=193, splitter=best; total time=  11.8s\n",
      "[CV] END ..criterion=entropy, max_depth=193, splitter=random; total time=  10.2s\n",
      "[CV] END ....criterion=entropy, max_depth=194, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=194, splitter=random; total time=  10.5s\n",
      "[CV] END ....criterion=entropy, max_depth=195, splitter=best; total time=  12.4s\n",
      "[CV] END ....criterion=entropy, max_depth=196, splitter=best; total time=  11.6s\n",
      "[CV] END ..criterion=entropy, max_depth=196, splitter=random; total time=  10.4s\n",
      "[CV] END ....criterion=entropy, max_depth=197, splitter=best; total time=  12.0s\n",
      "[CV] END ..criterion=entropy, max_depth=197, splitter=random; total time=  10.1s\n",
      "[CV] END ....criterion=entropy, max_depth=198, splitter=best; total time=  12.1s\n",
      "[CV] END ..criterion=entropy, max_depth=198, splitter=random; total time=  10.3s\n",
      "[CV] END ....criterion=entropy, max_depth=200, splitter=best; total time=  12.3s\n",
      "[CV] END .......criterion=gini, max_depth=180, splitter=best; total time=  13.6s\n",
      "[CV] END .....criterion=gini, max_depth=180, splitter=random; total time=  10.7s\n",
      "[CV] END .......criterion=gini, max_depth=181, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=181, splitter=random; total time=  10.6s\n",
      "[CV] END .......criterion=gini, max_depth=182, splitter=best; total time=  14.4s\n",
      "[CV] END .......criterion=gini, max_depth=183, splitter=best; total time=  13.8s\n",
      "[CV] END .....criterion=gini, max_depth=183, splitter=random; total time=  11.5s\n",
      "[CV] END .......criterion=gini, max_depth=184, splitter=best; total time=  14.4s\n",
      "[CV] END .....criterion=gini, max_depth=184, splitter=random; total time=  12.8s\n",
      "[CV] END .......criterion=gini, max_depth=185, splitter=best; total time=  14.8s\n",
      "[CV] END .......criterion=gini, max_depth=186, splitter=best; total time=  14.0s\n",
      "[CV] END .....criterion=gini, max_depth=186, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=187, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=187, splitter=random; total time=  11.3s\n",
      "[CV] END .......criterion=gini, max_depth=188, splitter=best; total time=  13.5s\n",
      "[CV] END .....criterion=gini, max_depth=188, splitter=random; total time=  10.5s\n",
      "[CV] END .......criterion=gini, max_depth=189, splitter=best; total time=  13.5s\n",
      "[CV] END .......criterion=gini, max_depth=190, splitter=best; total time=  14.3s\n",
      "[CV] END .....criterion=gini, max_depth=190, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=191, splitter=best; total time=  14.7s\n",
      "[CV] END .....criterion=gini, max_depth=191, splitter=random; total time=  12.0s\n",
      "[CV] END .......criterion=gini, max_depth=192, splitter=best; total time=  15.0s\n",
      "[CV] END .......criterion=gini, max_depth=193, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=193, splitter=random; total time=  12.6s\n",
      "[CV] END .......criterion=gini, max_depth=194, splitter=best; total time=  14.6s\n",
      "[CV] END .....criterion=gini, max_depth=194, splitter=random; total time=  11.1s\n",
      "[CV] END .......criterion=gini, max_depth=195, splitter=best; total time=  13.7s\n",
      "[CV] END .....criterion=gini, max_depth=195, splitter=random; total time=  11.7s\n",
      "[CV] END .......criterion=gini, max_depth=196, splitter=best; total time=  13.6s\n",
      "[CV] END .......criterion=gini, max_depth=197, splitter=best; total time=  14.2s\n",
      "[CV] END .....criterion=gini, max_depth=197, splitter=random; total time=  12.8s\n",
      "[CV] END .......criterion=gini, max_depth=198, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=198, splitter=random; total time=  11.4s\n",
      "[CV] END .......criterion=gini, max_depth=200, splitter=best; total time=  14.8s\n",
      "[CV] END .....criterion=gini, max_depth=200, splitter=random; total time=   7.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8196795 , 0.81473716, 0.81353901, 0.81908043, 0.81545836])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators= 200)\n",
    "cross_val_score(rf_clf, X_train,y_train.values.ravel(), cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45792cc3",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41d50e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestClassifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    grid_params = {'n_estimators': [50, 60, 70, 80],\n",
    "                   'max_depth': [230, 240, 250, 260],\n",
    "                   'min_samples_split': [20, 30, 40],\n",
    "                   'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "    rf_cv = GridSearchCV(estimator = rf_clf, \n",
    "                         param_grid=grid_params, \n",
    "                         cv =5, \n",
    "                         verbose=1, \n",
    "                         scoring = 'f1_weighted', \n",
    "                         n_jobs=-1)\n",
    "    \n",
    "    rf_cv.fit(X_train, y_train.values.ravel())\n",
    "    print(\"rf_cv.best_params_\", rf_cv.best_params_)\n",
    "    \n",
    "    rf_best = rf_cv.best_estimator_\n",
    "    y_predicted = rf_best.predict(X_test)\n",
    "    rf_accuracy = accuracy_score(y_test, y_predicted)\n",
    "    rf_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "    print(\"rf_accuracy, rf_f1\", rf_accuracy, rf_f1)\n",
    "\n",
    "    return rf_accuracy, rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601119d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "rf_cv.best_params_ {'max_depth': 200, 'min_samples_leaf': 2, 'min_samples_split': 39, 'n_estimators': 102}\n",
      "rf_accuracy, rf_f1 0.8285574503774112 0.8269197487384217\n",
      "a = 0.8285574503774112\n",
      "f = 0.8269197487384217\n",
      "CPU times: user 21.9 s, sys: 514 ms, total: 22.4 s\n",
      "Wall time: 21min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,f = randomForestClassifier(X_train, X_test, y_train, y_test)\n",
    "print(\"a =\", a)\n",
    "print(\"f =\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42f7a563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "rf_cv.best_params_ {'max_depth': 240, 'min_samples_leaf': 2, 'min_samples_split': 20, 'n_estimators': 50}\n",
      "rf_accuracy, rf_f1 0.8698630136986302 0.8533290537192774\n",
      "a_bin = 0.8698630136986302\n",
      "f_bin = 0.8533290537192774\n",
      "CPU times: user 14.7 s, sys: 930 ms, total: 15.6 s\n",
      "Wall time: 37min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_bin,f_bin = randomForestClassifier(X_bin_train, X_bin_test, y_bin_train, y_bin_test)\n",
    "print(\"a_bin =\", a_bin)\n",
    "print(\"f_bin =\", f_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6a05b",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcba1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xGboostClassifier(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    grid_params = {\"n_estimators\" : [int(x) for x in np.linspace(50, 500, num = 20)],\n",
    "        \"learning_rate\" : [ 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "        \"max_depth\" : [int(x) for x in np.linspace(100, 250, num = 20)],\n",
    "        \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "        \"gamma\" : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "        \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\n",
    "\n",
    "    xgb_clf = XGBClassifier()\n",
    "\n",
    "    xgb_cv = RandomizedSearchCV(estimator = xgb_clf, \n",
    "                                    param_distributions = grid_params,  \n",
    "                                    n_iter=50,\n",
    "                                    cv=2,\n",
    "                                    random_state=42, \n",
    "                                    n_jobs = -1, \n",
    "                                    scoring = 'f1_weighted')\n",
    "    xgb_cv.fit(X_train, y_train.values.ravel())\n",
    "    print(\"xgb_cv.best_params_\", xgb_cv.best_params_)\n",
    "    \n",
    "    xgb_best = xgb_cv.best_estimator_\n",
    "\n",
    "    y_predicted = xgb_best.predict(X_test)\n",
    "    xgb_accuracy = accuracy_score(y_test, y_predicted)\n",
    "    xgb_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "    print(\"xgb_accuracy, xgb_f1\", xgb_accuracy, xgb_f1)\n",
    "\n",
    "    return xgb_accuracy, xgb_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a163bb55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:20:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:42:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:31:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:31:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:05:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:49:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:55:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:57:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:32:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:10:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:35:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:27:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:39:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:26:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:23:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:56:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:39:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:32:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:11:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:13:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:03:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:40:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:59:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:37:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:23:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:12:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:56:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:50:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:27:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:54:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:59:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:17:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:32:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:24:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:12:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:48:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:30:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:32:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:27:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:09:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:15:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:04:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:47:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:45:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:34:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:47:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:18:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:10:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:46:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:46:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:22:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:09:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:27:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:47:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:38:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:18:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:16:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:54:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:22:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:35:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:55:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:07:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:58:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:15:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:57:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:23:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:22:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:19:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:57:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:43:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:58:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:31:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:25:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:00:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:22:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:12:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:32:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:53:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:47:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:30:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:45:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:11:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:44:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:01:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:32:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_cv.best_params_ {'n_estimators': 50, 'min_child_weight': 3, 'max_depth': 100, 'learning_rate': 0.15, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
      "xgb_accuracy, xgb_f1 0.8151383841207716 0.8179419349994229\n",
      "a = 0.8151383841207716\n",
      "f = 0.8179419349994229\n",
      "CPU times: user 1h 24min 11s, sys: 1min 36s, total: 1h 25min 47s\n",
      "Wall time: 1d 16h 20min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,f = xGboostClassifier(X_train, X_test, y_train, y_test)\n",
    "print(\"a =\", a)\n",
    "print(\"f =\", f)\n",
    "\n",
    "# xgb_cv.best_params_ {'n_estimators': 50, 'min_child_weight': 3, 'max_depth': 100, 'learning_rate': 0.15, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
    "# xgb_accuracy, xgb_f1 0.8151383841207716 0.8179419349994229\n",
    "# a = 0.8151383841207716\n",
    "# f = 0.8179419349994229\n",
    "# CPU times: user 1h 24min 11s, sys: 1min 36s, total: 1h 25min 47s\n",
    "# Wall time: 1d 16h 20min 19s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fa79ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:45:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:54:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:29:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:17:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:46:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:28:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:10:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:40:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:20:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:44:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:20:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:17:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:36:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:23:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:42:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:54:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:14:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:43:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:16:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:41:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:22:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:47:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:38:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:17:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:58:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:54:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:13:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:05:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:39:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:44:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:42:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:50:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:59:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:25:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:55:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:43:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:01:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:28:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:13:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:21:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:38:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:27:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:41:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:07:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:58:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:13:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:44:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:02:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:32:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:34:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:17:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:35:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:59:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:26:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:40:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:05:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:26:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:55:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:40:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:06:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:41:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:18:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:14:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:55:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:50:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:59:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:24:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:52:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:41:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:11:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:42:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:09:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:38:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:11:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:19:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:35:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:58:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:25:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:44:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:56:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:31:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:22:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:52:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:35:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:19:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:44:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:05:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:14:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_cv.best_params_ {'n_estimators': 144, 'min_child_weight': 1, 'max_depth': 250, 'learning_rate': 0.25, 'gamma': 0.4, 'colsample_bytree': 0.7}\n",
      "xgb_accuracy, xgb_f1 0.8470785574503774 0.8397420989282475\n",
      "a_bin = 0.8470785574503774\n",
      "f_bin = 0.8397420989282475\n",
      "CPU times: user 2h 35min 24s, sys: 2min 9s, total: 2h 37min 33s\n",
      "Wall time: 9h 25min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_bin,f_bin = xGboostClassifier(X_bin_train, X_bin_test, y_bin_train, y_bin_test)\n",
    "print(\"a_bin =\", a_bin)\n",
    "print(\"f_bin =\", f_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcf352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just 25 fits\n",
    "# xgb_cv.best_params_ {'n_estimators': 192, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.5}\n",
    "# a = 0.7813111545988258\n",
    "# f = 0.7832539672082043\n",
    "# CPU times: user 1min 54s, sys: 12.1 s, total: 2min 6s\n",
    "# Wall time: 8min 6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70c5f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xGboost(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    xgb_clf = XGBClassifier(n_estimators=200, max_depth=150)\n",
    "\n",
    "    print(\"Fitting the model\")\n",
    "    xgb_clf.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    y_predicted = xgb_clf.predict(X_test)\n",
    "    xgb_accuracy = accuracy_score(y_test, y_predicted)\n",
    "    xgb_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "\n",
    "    return xgb_accuracy, xgb_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebcacc9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:18:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "a = 0.8096169974839251\n",
      "f = 0.8126723079283034\n",
      "CPU times: user 12h 28min 54s, sys: 10min 54s, total: 12h 39min 48s\n",
      "Wall time: 1h 36min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,f = xGboost(X_train, X_test, y_train, y_test)\n",
    "print(\"a =\", a)\n",
    "print(\"f =\", f)\n",
    "\n",
    "# xgb_clf = XGBClassifier(n_estimators=150, max_depth=140)\n",
    "# a = 0.8029074643556052\n",
    "# f = 0.8059889605535215\n",
    "# CPU times: user 6h 16min 2s, sys: 6min 14s, total: 6h 22min 17s\n",
    "# Wall time: 50min 18s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cb97e",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dadddfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baggingClassifier(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    base_estimators = [DecisionTreeClassifier(criterion=\"entropy\", max_depth = 8),\n",
    "                       MultinomialNB(),\n",
    "                       LogisticRegression(solver='saga', n_jobs=-1,penalty='l2')]\n",
    "    \n",
    "    random_grid = {'base_estimator':base_estimators,\n",
    "                   'n_estimators': [20, 40, 60, 80, 100, 120],\n",
    "                   'max_samples': [1, 2, 5, 10, 25],\n",
    "                   'max_features': [1, 2, 4, 8, 16],\n",
    "                   'bootstrap': [True, False]}\n",
    "\n",
    "    bag = BaggingClassifier()\n",
    "    bag_cv = GridSearchCV(estimator = bag, \n",
    "                                    param_grid = random_grid,\n",
    "                                    cv = 10, \n",
    "                                    verbose = 2, \n",
    "                                    n_jobs=-1, \n",
    "                                    scoring = 'f1_weighted')\n",
    "    \n",
    "    bag_cv.fit(X_train, y_train.values.ravel())\n",
    "    print(\"bag_cv.best_params_\", bag_cv.best_params_)\n",
    "    \n",
    "    best_classifier = bag_cv.best_estimator_\n",
    "\n",
    "    y_predicted = best_classifier.predict(X_test)\n",
    "    bag_accuracy = accuracy_score(y_test, y_predicted)\n",
    "    bag_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "    print(\"bag_accuracy, bag_f1\", bag_accuracy, bag_f1)\n",
    "\n",
    "    return bag_accuracy, bag_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bf260e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   7.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  13.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   8.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  16.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   6.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  14.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   8.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   9.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  17.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   6.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   4.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.2s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  21.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   8.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  16.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   6.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  12.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   8.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  15.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  18.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   3.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  16.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=  10.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  19.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   4.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.6s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.5s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  14.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  18.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   7.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  17.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   4.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  17.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   8.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  14.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  14.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=SVC(gamma='auto'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  13.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  23.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  16.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   4.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.3s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.6s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   0.7s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=8), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   0.8s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=   1.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=   1.2s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   1.0s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   0.4s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   0.7s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=   0.9s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=   1.1s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=   1.3s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.6s\n",
      "[CV] END base_estimator=MultinomialNB(), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=1, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=10, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=1, max_samples=25, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=1, n_estimators=120; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=2, n_estimators=120; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=5, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=10, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   1.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=2, max_samples=25, n_estimators=120; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   6.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   7.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   9.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   8.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   7.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   8.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=  10.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   8.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=80; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=100; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=1, n_estimators=120; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   6.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=  10.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   6.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   7.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   7.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=  10.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=2, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=60; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=5, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=60; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=80; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=10, n_estimators=120; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   6.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   8.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=60; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=80; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=100; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=4, max_samples=25, n_estimators=120; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=40; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=60; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=80; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=100; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=1, n_estimators=120; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=40; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=60; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=80; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=100; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   8.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=  10.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   8.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  10.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=  10.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  12.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  27.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=2, n_estimators=120; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=40; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=60; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   7.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=  10.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   9.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  12.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=  13.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=  18.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  13.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  16.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  22.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  18.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  21.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   8.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=  10.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  10.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  18.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  21.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   8.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  10.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  14.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  16.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  20.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  24.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=  11.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=  12.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=  10.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   8.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=  10.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  12.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   8.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=   7.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  14.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  13.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   8.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=  13.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  13.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  15.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  10.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=  10.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  13.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  10.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  17.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  18.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=  10.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  11.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  12.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  17.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  17.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  24.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  13.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  14.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  20.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  23.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  28.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   8.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   8.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=  10.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=  10.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  12.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   7.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=  16.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  10.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  10.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  18.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   8.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   6.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=  12.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  15.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  14.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   7.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   9.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  14.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  11.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  19.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  18.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   6.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  10.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  18.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  21.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  23.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  22.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   8.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  15.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  20.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  24.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  23.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  26.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=80; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=100; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=5, n_estimators=120; total time=   8.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   7.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=  10.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   9.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  12.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  12.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=  10.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  13.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  12.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   8.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   8.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  15.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  12.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  17.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  13.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  19.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  18.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   8.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  11.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  19.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  17.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  17.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  25.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   7.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=  10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  13.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=60; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=80; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   6.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   8.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   9.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  11.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=20; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   8.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  19.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  16.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=  12.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  16.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  15.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  18.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   9.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=  12.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  14.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  13.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  17.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  19.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   8.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  11.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  20.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  22.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  19.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   9.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=  11.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  13.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  19.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  21.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  29.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=  11.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=  11.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  11.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=  11.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  13.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  19.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=20; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   9.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   8.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=  10.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  10.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  15.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  14.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  11.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  16.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  17.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  13.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  15.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  21.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  18.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  26.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  15.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  18.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  17.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  23.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  30.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=100; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=10, n_estimators=120; total time=  11.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=20; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=40; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=60; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=80; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=100; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  14.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=8, max_samples=25, n_estimators=120; total time=  11.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=60; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=80; total time=  12.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=100; total time=  18.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=1, n_estimators=120; total time=  18.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=40; total time=   8.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=  11.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  14.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  14.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  16.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   9.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=  11.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  11.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  19.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  21.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=20; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  10.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  16.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  11.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  17.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  22.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  25.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=  10.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  12.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  19.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  21.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  24.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  24.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=60; total time=  10.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=   7.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=80; total time=  11.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=100; total time=  14.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=2, n_estimators=120; total time=  13.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=20; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=40; total time=   8.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=60; total time=  10.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=80; total time=  11.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  14.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=100; total time=  18.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=5, n_estimators=120; total time=  21.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=40; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  11.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=60; total time=  14.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=80; total time=  17.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=100; total time=  22.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=10, n_estimators=120; total time=  27.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=20; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=40; total time=  10.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  15.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  17.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  17.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  23.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  30.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  13.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=60; total time=  15.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  17.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  21.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  27.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=80; total time=  19.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=100; total time=  23.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  26.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  26.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=1, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=True, max_features=16, max_samples=25, n_estimators=120; total time=  27.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=2, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=5, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   3.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=10, n_estimators=120; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=80; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=1, max_samples=25, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=80; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=1, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=60; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   3.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=2, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   5.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   5.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=80; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=5, n_estimators=120; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   6.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=  12.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   7.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=10, n_estimators=120; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=100; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=2, max_samples=25, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   5.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=  11.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=80; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=100; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=1, n_estimators=120; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=80; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=100; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=2, n_estimators=120; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   2.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=  13.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   2.7sbag_cv.best_params_ {'base_estimator': DecisionTreeClassifier(criterion='entropy', max_depth=8), 'bootstrap': True, 'max_features': 16, 'max_samples': 25, 'n_estimators': 100}\n",
      "bag_accuracy, bag_f1 0.4695974280123008 0.44616447726027625\n",
      "a = 0.4695974280123008\n",
      "f = 0.44616447726027625\n",
      "CPU times: user 35.9 s, sys: 5.78 s, total: 41.6 s\n",
      "Wall time: 40min 8s\n",
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=  13.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   6.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   7.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=  10.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   8.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  11.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  10.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=  11.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=  11.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  14.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   7.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   8.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  18.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  16.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   8.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=  10.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   9.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  10.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  14.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  16.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=  11.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  12.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  13.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  16.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  29.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=  11.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  13.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  14.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  16.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  22.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   8.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   8.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   7.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   8.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   9.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  13.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=  17.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=  11.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  12.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=  10.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  13.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  13.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  20.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=  11.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=  12.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  19.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  19.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  23.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=   7.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  10.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  16.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  20.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  27.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=  10.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  14.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  13.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  19.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  23.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   8.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=  11.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   9.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  11.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  12.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  11.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=  11.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=  17.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  18.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   7.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  12.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  11.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  21.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   9.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=  14.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  17.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  17.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   5.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=  10.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  12.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  12.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  19.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  20.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  20.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   8.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   7.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  12.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  18.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  17.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  23.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=  12.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   6.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   8.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=  11.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   8.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  10.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  15.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=  11.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=  17.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   7.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  18.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=  11.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  21.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  13.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   8.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  19.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  19.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  19.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   8.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  13.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  16.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  18.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  24.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  19.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   9.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  13.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  18.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  19.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  25.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  25.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=20; total time=   1.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=40; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=80; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=100; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=5, n_estimators=120; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   0.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=20; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=40; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=60; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=80; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=100; total time=   3.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=10, n_estimators=120; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=20; total time=   1.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   1.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=  10.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   3.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   7.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   7.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   9.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  10.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  11.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  13.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   3.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=  12.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=  13.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  16.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   2.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=  14.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  15.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  17.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   4.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=  11.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=  12.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  16.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  21.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   6.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   8.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  14.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  13.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  14.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  14.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  22.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  25.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  13.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  19.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  22.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  21.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  25.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   4.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   8.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   7.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   9.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   6.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   9.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  11.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  13.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  11.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=  11.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   9.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=  12.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=  14.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  12.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=20; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   1.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   8.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=   9.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  12.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  22.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   3.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   9.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   6.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=  16.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  16.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  19.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   4.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   8.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=  10.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  12.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  15.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  25.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   7.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  13.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  18.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  22.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  24.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   1.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=40; total time=   3.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   4.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   5.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   1.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   2.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   3.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   1.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   3.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   7.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   7.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   5.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   7.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=  10.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   6.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  11.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=  11.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  11.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   9.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=  11.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=  13.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  14.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=  10.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   9.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=  12.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  19.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=20; total time=   4.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   7.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=  11.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=  12.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  16.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  16.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  19.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   7.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  15.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  12.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  22.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  24.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  27.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=   9.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  15.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  18.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  23.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  27.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   2.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=40; total time=   2.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=60; total time=   2.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=80; total time=   4.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=100; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=4, max_samples=25, n_estimators=120; total time=   6.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=20; total time=   0.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   1.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=40; total time=   2.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=60; total time=   4.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=80; total time=   4.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=100; total time=   5.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   8.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=1, n_estimators=120; total time=   8.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=60; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=80; total time=   5.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=100; total time=   7.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   6.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=2, n_estimators=120; total time=   5.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=40; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=60; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=80; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=100; total time=   8.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   6.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=5, n_estimators=120; total time=   8.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=40; total time=   3.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=60; total time=   4.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=80; total time=   9.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=100; total time=   9.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=10, n_estimators=120; total time=   9.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   2.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=20; total time=   1.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=40; total time=   5.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=60; total time=   7.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=80; total time=   9.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=100; total time=   9.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=8, max_samples=25, n_estimators=120; total time=  12.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   5.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=20; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   1.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=40; total time=   3.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   2.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=60; total time=   6.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=80; total time=  15.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=100; total time=   9.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  12.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=1, n_estimators=120; total time=  16.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=40; total time=   2.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=60; total time=   7.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=80; total time=  12.0s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=100; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  18.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=2, n_estimators=120; total time=  17.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=   5.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=40; total time=  10.4s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=60; total time=   9.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=80; total time=  13.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=100; total time=  18.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=5, n_estimators=120; total time=  18.1s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   3.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=20; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   5.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=40; total time=   7.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=60; total time=  12.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=80; total time=  16.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  19.3s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=100; total time=  19.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=10, n_estimators=120; total time=  24.8s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=20; total time=   4.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=40; total time=  11.5s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=60; total time=  17.2s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=80; total time=  21.6s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=100; total time=  26.9s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  25.7s\n",
      "[CV] END base_estimator=LogisticRegression(n_jobs=-1, solver='saga'), bootstrap=False, max_features=16, max_samples=25, n_estimators=120; total time=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/ensemble_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,f = baggingClassifier(X_train, X_test, y_train, y_test)\n",
    "print(\"a =\", a)\n",
    "print(\"f =\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c156a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
